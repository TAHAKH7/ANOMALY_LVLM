Project Introduction
====================
------------------------------------------

AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models
___________________________


.. raw:: html

    <p style="text-align: justify;"><span style="color:#000080;">

    AnomalyGPT is an innovative conversational vision-language model (LVLM) designed to address Industrial Anomaly Detection (IAD). Leveraging state-of-the-art LVLMs, AnomalyGPT overcomes challenges faced by traditional IAD methods, such as reliance on manual thresholds and limited adaptability to unseen object categories. This model integrates pre-trained language and vision modules to enable automated detection, precise anomaly localization, and interactive dialogue capabilities.

   </span></p>

.. figure:: /Documentation/images/compare.jpg
   :width: 700
   :align: center
   :alt: Alternative text for the image

.. raw:: html

    <p style="text-align: justify;"><i>
    <br>
    - <span style="color:blue;">Key Features :</span><span style="color:#000080;"><br>
      Automated Anomaly Judgments: Eliminates the need for manual threshold adjustments.<br>
      Pixel-Level Localization: Detects anomalies with high precision.<br>
      Few-Shot Learning: Adapts to new datasets using a single normal sample.<br>
      Multi-Turn Dialogue: Provides interactive insights for industrial anomaly detection.
    </span></i>
   </p>



    <p style="text-align: justify;"><i>

    <span style="color:blue;">Input : </span><span style="color:#000080;"><br>
      -Image Input:<br>
      High-resolution industrial images of artifacts or components.<br>
      Example datasets: MVTec-AD and VisA, which contain normal and anomalous images of various objects like screws, cables, and industrial parts.<br>
      -Textual Queries:<br>
      User-generated natural language queries to specify the type of anomaly analysis required, for example : "Is there an anomaly in the image?" , "Highlight the anomalies in this image."<br>
      -Pre-trained Models:<br>
      Inputs include the embeddings generated by the pre-trained ImageBind and Vicuna-7B models.<br>
      Localization maps generated by the Feature-Matching Decoder.<br>
      -Few-Shot Reference Images:<br>
      A small set of normal reference images for the same object category (used for comparison in few-shot learning).<br>
    </i></span></p>


    <p style="text-align: justify;"><i>

    <span style="color:blue;">Output : </span><span style="color:#000080;"><br>
      -Image-Level Output:<br>
      Indicates whether an image contains anomalies.<br>
      Example: "The image contains anomalies." or "No anomaly detected."<br>
      -Localization Results:<br>
      Pixel-Level Localization: Outputs a heatmap or segmentation mask highlighting the anomalous regions.<br>
      -Textual Descriptions:<br>
      Generated natural language descriptions explaining the anomalies detected.<br>
      Example: "There is a scratch on the metallic surface." , "A crack is detected in the upper-right corner of the component."<br>
      -Interactive Responses:<br>
      Multi-turn dialogue providing detailed explanations and follow-up insights based on user queries.<br>
      Example interaction:<br>
      User: "Is there a defect in this image?"<br>
      System: "Yes, the anomaly is a surface deformation near the center."<br>
      User: "Can you describe it more precisely?"<br>
      System: "The deformation appears to be a dent with an approximate size of 2cm by 3cm."<br>
    </i></span></p>

    <span style="color:blue;">Example : </span><span style="color:#000080;"><br>
    </i></span></p>
   

.. figure:: /Documentation/images/anomalygpt_im.jpg
   :width: 100%
   :alt: Alternative text for the image
   :name: logo
   


Documentation axes
_________________________

.. raw:: html

    <p style="text-align: justify;"><span style="color:#000080;">
    -AI MODULES FOR AnomalyGPT
    -Running AnomalyGPT Demo
    -Train Your Own AnomalyGPT
    
   </span></p>

